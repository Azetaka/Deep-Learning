{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w491pA49yoEo"
      },
      "source": [
        "**Avant de débuter ce TP** :\n",
        "\n",
        "1. **Changez le type d'exécution sur Google Colab** : `Exécution > Modifiez le type d'exécution > T4 GPU`\n",
        "2. **Installez les paquets ci-dessous** :"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "aTFc6OivyoEq",
        "outputId": "775c1dc5-2adf-4d89-c2f3-9bddf48728a7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting lightning\n",
            "  Downloading lightning-2.5.5-py3-none-any.whl.metadata (39 kB)\n",
            "Collecting torchmetrics\n",
            "  Downloading torchmetrics-1.8.2-py3-none-any.whl.metadata (22 kB)\n",
            "Collecting torchinfo\n",
            "  Downloading torchinfo-1.8.0-py3-none-any.whl.metadata (21 kB)\n",
            "Requirement already satisfied: PyYAML<8.0,>5.4 in /usr/local/lib/python3.12/dist-packages (from lightning) (6.0.3)\n",
            "Requirement already satisfied: fsspec<2027.0,>=2022.5.0 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<2027.0,>=2022.5.0->lightning) (2025.3.0)\n",
            "Collecting lightning-utilities<2.0,>=0.10.0 (from lightning)\n",
            "  Downloading lightning_utilities-0.15.2-py3-none-any.whl.metadata (5.7 kB)\n",
            "Requirement already satisfied: packaging<27.0,>=20.0 in /usr/local/lib/python3.12/dist-packages (from lightning) (25.0)\n",
            "Requirement already satisfied: torch<4.0,>=2.1.0 in /usr/local/lib/python3.12/dist-packages (from lightning) (2.8.0+cu126)\n",
            "Requirement already satisfied: tqdm<6.0,>=4.57.0 in /usr/local/lib/python3.12/dist-packages (from lightning) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions<6.0,>4.5.0 in /usr/local/lib/python3.12/dist-packages (from lightning) (4.15.0)\n",
            "Collecting pytorch-lightning (from lightning)\n",
            "  Downloading pytorch_lightning-2.5.5-py3-none-any.whl.metadata (20 kB)\n",
            "Requirement already satisfied: numpy>1.20.0 in /usr/local/lib/python3.12/dist-packages (from torchmetrics) (2.0.2)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<2027.0,>=2022.5.0->lightning) (3.13.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from lightning-utilities<2.0,>=0.10.0->lightning) (75.2.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch<4.0,>=2.1.0->lightning) (3.20.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch<4.0,>=2.1.0->lightning) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch<4.0,>=2.1.0->lightning) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch<4.0,>=2.1.0->lightning) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch<4.0,>=2.1.0->lightning) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch<4.0,>=2.1.0->lightning) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch<4.0,>=2.1.0->lightning) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch<4.0,>=2.1.0->lightning) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch<4.0,>=2.1.0->lightning) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch<4.0,>=2.1.0->lightning) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch<4.0,>=2.1.0->lightning) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch<4.0,>=2.1.0->lightning) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch<4.0,>=2.1.0->lightning) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch<4.0,>=2.1.0->lightning) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch<4.0,>=2.1.0->lightning) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch<4.0,>=2.1.0->lightning) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch<4.0,>=2.1.0->lightning) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch<4.0,>=2.1.0->lightning) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch<4.0,>=2.1.0->lightning) (3.4.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2027.0,>=2022.5.0->lightning) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2027.0,>=2022.5.0->lightning) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2027.0,>=2022.5.0->lightning) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2027.0,>=2022.5.0->lightning) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2027.0,>=2022.5.0->lightning) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2027.0,>=2022.5.0->lightning) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2027.0,>=2022.5.0->lightning) (1.22.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch<4.0,>=2.1.0->lightning) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch<4.0,>=2.1.0->lightning) (3.0.3)\n",
            "Requirement already satisfied: idna>=2.0 in /usr/local/lib/python3.12/dist-packages (from yarl<2.0,>=1.17.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2027.0,>=2022.5.0->lightning) (3.10)\n",
            "Downloading lightning-2.5.5-py3-none-any.whl (828 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m828.5/828.5 kB\u001b[0m \u001b[31m15.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torchmetrics-1.8.2-py3-none-any.whl (983 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m983.2/983.2 kB\u001b[0m \u001b[31m33.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torchinfo-1.8.0-py3-none-any.whl (23 kB)\n",
            "Downloading lightning_utilities-0.15.2-py3-none-any.whl (29 kB)\n",
            "Downloading pytorch_lightning-2.5.5-py3-none-any.whl (832 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m832.4/832.4 kB\u001b[0m \u001b[31m46.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: torchinfo, lightning-utilities, torchmetrics, pytorch-lightning, lightning\n",
            "Successfully installed lightning-2.5.5 lightning-utilities-0.15.2 pytorch-lightning-2.5.5 torchinfo-1.8.0 torchmetrics-1.8.2\n"
          ]
        }
      ],
      "source": [
        "! pip install lightning torchmetrics torchinfo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KV6JSJY7yoEr"
      },
      "source": [
        "3. Exécutez ce code pour supprimer quelques messages et avertissements éventuellement affichés."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "-sOxUFNIyoEr"
      },
      "outputs": [],
      "source": [
        "import logging\n",
        "logging.getLogger(\"lightning\").setLevel(logging.ERROR)\n",
        "logging.getLogger(\"lightning.pytorch.utilities.rank_zero\").setLevel(logging.WARNING)\n",
        "logging.getLogger(\"lightning.pytorch.accelerators.cuda\").setLevel(logging.WARNING)\n",
        "logger = logging.getLogger(\"lightning\")\n",
        "logger.propagate = False\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\", \".*does not have many workers.*\")\n",
        "warnings.filterwarnings(\"ignore\", \".*Missing logger folder.*\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UjQplG-myoEs"
      },
      "source": [
        "# Classification d'images par réseau de neurones convolutif\n",
        "\n",
        "## Chargement des données\n",
        "\n",
        "Nous allons travailler sur un jeu de données appelé [EMNIST](https://www.westernsydney.edu.au/icns/resources/reproducible_research3/publication_support_materials2/emnist), et plus spécifiquement sur un sous-jeu de données constitué d'images en nuances de gris de lettres manuscrites.\n",
        "Pour ce faire, nous allons utiliser la classe [`torchvision.datasets.EMNIST()`](https://pytorch.org/vision/stable/generated/torchvision.datasets.EMNIST.html) pour télécharger et charger ce jeu de données."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "9Ie3py0SyoEs",
        "outputId": "2e96996e-a885-4eea-ff3e-c30af31458f3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 562M/562M [00:04<00:00, 139MB/s] \n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from torchvision.datasets import EMNIST\n",
        "from torchvision.transforms import v2\n",
        "\n",
        "\n",
        "dataset_train = EMNIST(\n",
        "    root='data',\n",
        "    split='letters',\n",
        "    download=True,\n",
        "    train=True,\n",
        "    transform=v2.Compose([v2.ToImage(), v2.ToDtype(torch.float32, scale=True)]),\n",
        "    target_transform=lambda x: x - 1\n",
        ")\n",
        "\n",
        "dataset_val = EMNIST(\n",
        "    root='data',\n",
        "    split='letters',\n",
        "    download=True,\n",
        "    train=False,\n",
        "    transform=v2.Compose([v2.ToImage(), v2.ToDtype(torch.float32, scale=True)]),\n",
        "    target_transform=lambda x: x - 1\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XwYTpEKGyoEt"
      },
      "source": [
        "### Question 1\n",
        "\n",
        "**a)** Calculer la taille des jeux d'entraînement et de validation, c'est-à-dire le nombre d'images dans chacun des deux jeux.\n",
        "\n",
        "**b)** Calculer la taille d'une observation, c'est-à-dire la taille d'une image. On prendra pour acquis que toutes les observations ont la même taille (c'est bien le cas, vous n'avez pas à le vérifier)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "38nJQJCEyoEt",
        "outputId": "7fa18947-e4cf-48bc-cae5-77cee0893ded",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Taille du jeu d'entraînement : 124800\n",
            "Taille du jeu de validation : 20800\n",
            "Taille d'une observation : torch.Size([1, 28, 28])\n"
          ]
        }
      ],
      "source": [
        "# a) Taille du jeu d'entraînement et validation\n",
        "print(f\"Taille du jeu d'entraînement : {len(dataset_train)}\")\n",
        "print(f\"Taille du jeu de validation : {len(dataset_val)}\")\n",
        "# b) Taille d'une observation\n",
        "print(f\"Taille d'une observation : {dataset_train[0][0].shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oocURQrNyoEt"
      },
      "source": [
        "Il y a 26 classes dans ce jeu de données, correspondant aux 26 lettres de l'alphabet. Néanmoins, le jeu de données mélange les lettres majuscules et minuscules : des images pour les lettres *A* et *a* ont donc le même label.\n",
        "\n",
        "Le code ci-dessous permet d'afficher neuf observations tirées aléatoirement dans le jeu d'entraînement."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "_eE5SsKOyoEu",
        "outputId": "0a1c8285-c231-430c-b7d5-452adec82f6d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 675
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x800 with 9 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "figure = plt.figure(figsize=(8, 8))\n",
        "cols, rows = 3, 3\n",
        "for i in range(1, cols * rows + 1):\n",
        "    sample_idx = torch.randint(len(dataset_train), size=(1,)).item()\n",
        "    img, label = dataset_train[sample_idx]\n",
        "    figure.add_subplot(rows, cols, i)\n",
        "    plt.title(f\"{chr(65 + label)} ou {chr(97 + label)}\")\n",
        "    plt.axis(\"off\")\n",
        "    plt.imshow(img.squeeze().T, cmap=\"gray\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m5l9ouAMyoEu"
      },
      "source": [
        "### Question 2\n",
        "\n",
        "Vous avez peut-être remarqué le code suivant dans la création des jeux de données :\n",
        "\n",
        "```python\n",
        "transform=v2.Compose([v2.ToImage(), v2.ToDtype(torch.float32, scale=True)],\n",
        "target_transform=lambda x: x - 1\n",
        "```\n",
        "\n",
        "En lisant la documentation de la classe [`torchvision.datasets.EMNIST()`](https://pytorch.org/vision/stable/generated/torchvision.datasets.EMNIST.html), vous verrez que :\n",
        "* l'argument `transform` permet de transformer l'image brute,\n",
        "* l'argument `target_transform` permet de transformer le label.\n",
        "\n",
        "**a)** Expliquez l'utilité du code transformant les entrées. Pour ce faire, pour la première observation du jeu d'entraînement, affichez le tenseur de l'entrée brute et le tenseur de l'entrée transformée. En particulier, comparez la taille, le type de données (*dtype*) et les valeurs minimale et maximale pour ces deux tenseurs.\n",
        "\n",
        "> **Remarque** : vous pouvez accéder aux données brutes de ce jeu de données grâce à l'attribut `data` (par exemple `dataset_train.data`)\n",
        "\n",
        "**b)** Expliquez l'utilité du code transformant les labels.\n",
        "\n",
        "> **Remarque** : vous pouvez accéder à la correspondance des labels bruts de ce jeu de données grâce à l'attribut `class_to_idx` (par exemple `dataset_train.class_to_idx`). Vous admettrez, sans le vérifier, qu'il n'y a aucun label manquant (`'N/A'`) dans les deux jeux de données."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "SCssFpWuyoEu",
        "outputId": "98414857-ac82-4691-a390-13e4fefca01e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'torch.Tensor'>\n"
          ]
        }
      ],
      "source": [
        "# a)Explication du code transformant les entrées\n",
        "  # Tenseur de l'entrée brute\n",
        "  # Tenseur de l'entrée transformée\n",
        "#print(dataset_train[0][0].shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A5ziK4uVyoEu"
      },
      "source": [
        "**Réponses** :\n",
        "    \n",
        "**a)** TODO\n",
        "\n",
        "**b)** TODO"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sfPH8a6VyoEu"
      },
      "source": [
        "### Question 3\n",
        "\n",
        "Calculez la distribution des classes sur les jeux d'entraînement et de validation. Est-ce que les classes sont équilibrées ? Est-ce que l'exactitude (*accuracy*) est une métrique adaptée pour évaluer la performance d'un modèle ? Vous pouvez utiliser, au choix, les fonctions [`numpy.unique()`](https://numpy.org/doc/stable/reference/generated/numpy.unique.html), [`numpy.bincount()`](https://numpy.org/doc/stable/reference/generated/numpy.bincount.html) ou [`torch.bincount()`](https://pytorch.org/docs/stable/generated/torch.bincount.html) pour vous aider."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "b5358LccyoEv",
        "outputId": "c8c9762f-1a03-4edd-cfbb-20c4512b39c3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classes : [ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24\n",
            " 25 26]\n",
            "Nombre de classes : 26\n",
            "{np.int64(1): 4800, np.int64(2): 4800, np.int64(3): 4800, np.int64(4): 4800, np.int64(5): 4800, np.int64(6): 4800, np.int64(7): 4800, np.int64(8): 4800, np.int64(9): 4800, np.int64(10): 4800, np.int64(11): 4800, np.int64(12): 4800, np.int64(13): 4800, np.int64(14): 4800, np.int64(15): 4800, np.int64(16): 4800, np.int64(17): 4800, np.int64(18): 4800, np.int64(19): 4800, np.int64(20): 4800, np.int64(21): 4800, np.int64(22): 4800, np.int64(23): 4800, np.int64(24): 4800, np.int64(25): 4800, np.int64(26): 4800}\n"
          ]
        }
      ],
      "source": [
        "# Distribution des classes\n",
        "#torch.bincount(torch.tensor(dataset_train.targets - 1))\n",
        "import numpy as np\n",
        "# Liste des classes\n",
        "classes = np.unique(dataset_train.targets)\n",
        "print(\"Classes :\", classes)\n",
        "# Nombre de classes\n",
        "print(\"Nombre de classes :\", len(classes))\n",
        "dictionnaire = {}\n",
        "for i in classes:\n",
        "    dictionnaire[i] = np.count_nonzero(dataset_train.targets == i)\n",
        "print(dictionnaire)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Liste des classes\n",
        "classes_1 = np.unique(dataset_val.targets)\n",
        "print(\"Classes :\", classes)\n",
        "# Nombre de classes\n",
        "print(\"Nombre de classes :\", len(classes_1))\n",
        "dictionnaire = {}\n",
        "for i in classes:\n",
        "    dictionnaire[i] = np.count_nonzero(dataset_val.targets == i)\n",
        "print(dictionnaire)"
      ],
      "metadata": {
        "id": "KDDME-tz8Mkc",
        "outputId": "eb231139-848c-4afd-d670-ce3e041074ac",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classes : [ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24\n",
            " 25 26]\n",
            "Nombre de classes : 26\n",
            "{np.int64(1): 800, np.int64(2): 800, np.int64(3): 800, np.int64(4): 800, np.int64(5): 800, np.int64(6): 800, np.int64(7): 800, np.int64(8): 800, np.int64(9): 800, np.int64(10): 800, np.int64(11): 800, np.int64(12): 800, np.int64(13): 800, np.int64(14): 800, np.int64(15): 800, np.int64(16): 800, np.int64(17): 800, np.int64(18): 800, np.int64(19): 800, np.int64(20): 800, np.int64(21): 800, np.int64(22): 800, np.int64(23): 800, np.int64(24): 800, np.int64(25): 800, np.int64(26): 800}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Ou fais tout simplement\n",
        "# Comptage du nombre d'images par classe\n",
        "train_counts = torch.bincount(dataset_train.targets-1)\n",
        "valid_counts = torch.bincount(dataset_val.targets-1)\n",
        "print(\"Distribution des classes - Entraînement :\", train_counts)\n",
        "print(\"Distribution des classes - Validation :\", valid_counts)"
      ],
      "metadata": {
        "id": "kNCZdkZz9ODV",
        "outputId": "7c17c84a-91bf-4244-857b-e651be8a05d9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Distribution des classes - Entraînement : tensor([4800, 4800, 4800, 4800, 4800, 4800, 4800, 4800, 4800, 4800, 4800, 4800,\n",
            "        4800, 4800, 4800, 4800, 4800, 4800, 4800, 4800, 4800, 4800, 4800, 4800,\n",
            "        4800, 4800])\n",
            "Distribution des classes - Validation : tensor([800, 800, 800, 800, 800, 800, 800, 800, 800, 800, 800, 800, 800, 800,\n",
            "        800, 800, 800, 800, 800, 800, 800, 800, 800, 800, 800, 800])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hLK0MPKXyoEv"
      },
      "source": [
        "### Question 4\n",
        "\n",
        "Construisez les *dataloaders* pour les jeux d'entraînement et de validation. Vous utiliserez des lots de taille *64*. Mélangez les observations sur le jeu d'entraînement."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6yksSJTpyoEv"
      },
      "outputs": [],
      "source": [
        "# TODO"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1AEhuE9UyoEv"
      },
      "source": [
        "## Un premier réseau de neurones convolutif\n",
        "\n",
        "### Question 5\n",
        "\n",
        "Le code suivant est l'ébauche de la définition d'un réseau de neurones convolutif. Répondez aux questions suivantes :\n",
        "\n",
        "**a)** Quelles couches sont des couches de convolution ?\n",
        "\n",
        "**b)** Pourquoi le nombre de canaux en entrée est fixé à `1` dans `self.cv1` ?\n",
        "\n",
        "**c)** Indiquez, pour `self.cv1`, le nombre de canaux en sortie, la taille du noyau et la taille du pas.\n",
        "\n",
        "**d)** De quel type de couche de regroupement ce réseau est-il constitué ?\n",
        "\n",
        "**e)** Quelles sont les couches avec des paramètres entraînables ?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SYB9LMySyoEv"
      },
      "outputs": [],
      "source": [
        "import lightning as L\n",
        "from torchmetrics import Accuracy\n",
        "\n",
        "\n",
        "class CNN(L.LightningModule):  # La classe hérite de la classe lightning.LightningModule\n",
        "    def __init__(self):\n",
        "        \"\"\"Constructeur.\n",
        "\n",
        "        Dans le constructeur, on exécute le constructeur de la clase mère et on définit\n",
        "        toutes les couches et fonctions d'activation de notre réseau de neurones.\n",
        "        \"\"\"\n",
        "        super().__init__()  # Toujours exécuter le constructeur de la classe mère\n",
        "\n",
        "        # Initialisation des couches et fonctions d'activation\n",
        "        self.cv1 = torch.nn.Conv2d(in_channels=1, out_channels=4, kernel_size=5, padding='same')\n",
        "        self.relu1 = torch.nn.ReLU()\n",
        "        self.pool1 = torch.nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        self.flatten = torch.nn.Flatten()\n",
        "        self.fc2 = torch.nn.Linear(123, 64)\n",
        "        self.relu2 = torch.nn.ReLU()\n",
        "        self.fc3 = torch.nn.Linear(64, 26)\n",
        "        self.relu3 = torch.nn.ReLU()\n",
        "\n",
        "        # Initialisation de la fonction de perte\n",
        "        self.loss = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "        # Initialisation des métriques\n",
        "        self.accuracy_train = Accuracy(task=\"multiclass\", num_classes=26)\n",
        "        self.accuracy_val = Accuracy(task=\"multiclass\", num_classes=26)\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"Implémente la passe avant.\n",
        "\n",
        "        L'argument x est un tenseur correspondant soit à l'entrée une seule\n",
        "        observation soit aux entrées d'un lot d'observations.\n",
        "        \"\"\"\n",
        "        out = self.cv1(x)\n",
        "        out = self.relu1(out)\n",
        "        out = self.pool1(out)\n",
        "        out = self.flatten(out)\n",
        "        out = self.fc2(out)\n",
        "        out = self.relu2(out)\n",
        "        out = self.fc3(out)\n",
        "        out = self.relu3(out)\n",
        "        return out\n",
        "\n",
        "    def step(self, batch, dataset):\n",
        "        \"\"\"Effectue une étape.\n",
        "\n",
        "        Une étape consiste à passer d'un lot d'observations (l'argument batch)\n",
        "        à l'évaluation de la fonction de coût pour ce lot d'observations.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        batch : tuple\n",
        "            Un lot d'observations. Le premier élément du tuple est le lot\n",
        "            des entrées, le second est le lot des labels.\n",
        "\n",
        "        dataset : {\"training\", \"validation\"}\n",
        "            Jeu de données utilisé.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        loss : Tensor, shape = (1,)\n",
        "            La fonction de coût pour ce lot d'observations.\n",
        "        \"\"\"\n",
        "        X, y = batch  # X correspond aux images, y aux classes\n",
        "        logits = self(X)  # Passe avant, qui renvoie les logits\n",
        "        loss = self.loss(logits, y)  # Évaluation de la fonction de coût\n",
        "        y_pred = logits.argmax(1)  # Prédictions du modèle\n",
        "\n",
        "        if dataset == \"training\":\n",
        "            metric = self.accuracy_train\n",
        "            name = \"train\"\n",
        "            bar_step = True\n",
        "        else:\n",
        "            metric = self.accuracy_val\n",
        "            name = \"val\"\n",
        "            bar_step = False\n",
        "\n",
        "        acc = metric(y_pred, y)\n",
        "        self.log(f\"loss_{name}\", loss, prog_bar=bar_step, on_step=bar_step, on_epoch=True)\n",
        "        self.log(f\"accuracy_{name}\", acc, prog_bar=bar_step, on_step=bar_step, on_epoch=True)\n",
        "\n",
        "        return loss\n",
        "\n",
        "    def training_step(self, batch):\n",
        "        \"\"\"Effectue une étape d'entraînement.\"\"\"\n",
        "        return self.step(batch, \"training\")\n",
        "\n",
        "    def validation_step(self, batch):\n",
        "        \"\"\"Effectue une étape de validation.\"\"\"\n",
        "        return self.step(batch, \"validation\")\n",
        "\n",
        "    def on_train_start(self):\n",
        "        \"\"\"Code exécuté au début de l'entraînement.\"\"\"\n",
        "        string = f\"Version {self.trainer.logger.version}\"\n",
        "        print(f\"{string}\\n{'=' * len(string)}\\n\")\n",
        "\n",
        "    def on_train_epoch_end(self):\n",
        "        \"\"\"Code exécuté à la fin de chaque époque d'entraînement.\"\"\"\n",
        "        metrics = self.trainer.callback_metrics\n",
        "        string = (f\"\"\"\n",
        "            Époque {self.trainer.current_epoch + 1} / {self.trainer.max_epochs}\n",
        "            -------------------------------------------------\n",
        "            |     Jeu      | Fonction de perte | Exactitude |\n",
        "            | ------------ | ----------------- | ---------- |\n",
        "            | Entraînement |{metrics['loss_train'].item():^19.5f}|{metrics['accuracy_train'].item():^11.3%}|\n",
        "            |  Validation  |{metrics['loss_val'].item():^19.5f}|{metrics['accuracy_val'].item():^11.3%}|\n",
        "            -------------------------------------------------\n",
        "        \"\"\")\n",
        "        string = '\\n'.join([line.strip() for line in string.strip().split('\\n')])\n",
        "        print(string, \"\\n\")\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        \"\"\"Configure l'algorithme d'optimisation à utiliser.\"\"\"\n",
        "        optimizer = torch.optim.Adam(self.parameters())\n",
        "        return optimizer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NUkyiqxFyoEv"
      },
      "source": [
        "**Réponses** :\n",
        "\n",
        "**a)** TODO\n",
        "\n",
        "**b)** TODO\n",
        "\n",
        "**c)** TODO\n",
        "\n",
        "**d)** TODO\n",
        "\n",
        "**e)** TODO"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GTTERkazyoEv"
      },
      "source": [
        "### Question 6\n",
        "\n",
        "En essayant d'afficher le résumé de l'architecture de notre modèle avec le code ci-dessous, une erreur va être levée. Identifiez le problème correspondant à cette erreur et corrigez-le. Indiquez, avec des mots, quel était le problème."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fM7VQfAfyoEv"
      },
      "outputs": [],
      "source": [
        "from torchinfo import summary\n",
        "\n",
        "\n",
        "summary(CNN(), input_size=(64, 1, 28, 28))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U5HReWCmyoEw"
      },
      "source": [
        "**Réponse** : TODO"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o9PaCmMjyoEw"
      },
      "source": [
        "### Question 7\n",
        "\n",
        "Entraînez votre modèle pendant 10 époques. Comparez la performance du modèle à celle attendue pour un modèle trivial (qui prédirait toujours la même classe ou qui prédirait de façon totalement aléatoire les classes)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FNP0HqX2yoEw"
      },
      "outputs": [],
      "source": [
        "from lightning.pytorch.callbacks import TQDMProgressBar\n",
        "from lightning.pytorch.loggers import CSVLogger\n",
        "\n",
        "\n",
        "model = CNN()\n",
        "\n",
        "trainer = L.Trainer(\n",
        "    max_epochs=10,\n",
        "    enable_model_summary=False,  # supprimer le résumé du modèle\n",
        "    logger=CSVLogger('.'),  # sauvegarder les résultats dans un fichier CSV\n",
        "    num_sanity_val_steps=0,  # ne pas effectuer d'étape de validation avant l'entraînement\n",
        "    callbacks=[TQDMProgressBar(refresh_rate=100)]  # mettre à jour la barre de progression tous les 100 lots\n",
        ")\n",
        "\n",
        "trainer.fit(\n",
        "    model=model,\n",
        "    train_dataloaders=dataloader_train,\n",
        "    val_dataloaders=dataloader_val\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z6DqZUNiyoEw"
      },
      "source": [
        "**Réponse** : TODO"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zOcHuY3GyoEw"
      },
      "source": [
        "### Question 8\n",
        "\n",
        "Viusalisez les courbes de performance du modèle en utilisant la fonction `plot_loss_accuracy` définie ci-dessous. Vous pouvez utiliser l'argument `version` pour indiquer quelle version du modèle choisir."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5Jx5U8ffyoEw"
      },
      "outputs": [],
      "source": [
        "def plot_loss_accuracy(savedir='.', version=None):\n",
        "    \"\"\"Affiche les courbes de la fonction de perte et d'accuracy.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    savedir : str (default = '.')\n",
        "        Chemin où les résultats sont sauvegardés.\n",
        "\n",
        "    version : int or None (default = None)\n",
        "        Numéro de la version du modèle.\n",
        "    \"\"\"\n",
        "    # Récupère les résultats sous la forme d'un DataFrame\n",
        "    import os\n",
        "    import pandas as pd\n",
        "    if version is None:\n",
        "        version = max([\n",
        "            int(folder.split('version_')[1])\n",
        "            for folder in os.listdir(os.path.join(savedir, 'lightning_logs'))\n",
        "            if folder.startswith('version')\n",
        "        ])\n",
        "    df = pd.read_csv(os.path.join(savedir, 'lightning_logs', f'version_{version}', 'metrics.csv'))\n",
        "    df['epoch'] += 1  # On commence à compter à partir de 1\n",
        "\n",
        "    loss_train = df.dropna(subset='loss_train_epoch').set_index('epoch')['loss_train_epoch']\n",
        "    loss_val = df.dropna(subset='loss_val').set_index('epoch')['loss_val']\n",
        "\n",
        "    accuracy_train = df.dropna(subset='accuracy_train_epoch').set_index('epoch')['accuracy_train_epoch']\n",
        "    accuracy_val = df.dropna(subset='accuracy_val').set_index('epoch')['accuracy_val']\n",
        "\n",
        "    # Affiche les résultats\n",
        "    plt.figure(figsize=(13, 4))\n",
        "\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(loss_train.index, loss_train.to_numpy(), 'o-', label='Entraînement');\n",
        "    plt.plot(loss_val.index, loss_val.to_numpy(), 'o-', label='Validation');\n",
        "    plt.xlabel('Époque')\n",
        "    plt.ylabel('Fonction de perte')\n",
        "    plt.legend();\n",
        "\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(accuracy_train.index, accuracy_train.to_numpy(), 'o-', label='Entraînement');\n",
        "    plt.plot(accuracy_val.index, accuracy_val.to_numpy(), 'o-', label='Validation');\n",
        "    plt.xlabel('Époque')\n",
        "    plt.ylabel('Précision')\n",
        "    plt.legend();"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CVAcXEx4yoEw"
      },
      "outputs": [],
      "source": [
        "plot_loss_accuracy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2q7ji7O-yoEw"
      },
      "source": [
        "## Un deuxième réseau de neurones convolutif\n",
        "\n",
        "### Question 9\n",
        "\n",
        "Complétez la méthode `__init__()` de la classe `LeNet5` définie ci-dessous dont l'achitecture séquentielle est décrite ci-dessous, correspondant à l'architecture de [LeNet5](https://en.wikipedia.org/wiki/LeNet) :\n",
        "\n",
        "* une couche de convolution avec $6$ canaux en sortie, un noyau de taille $5 \\times 5$ et du rembourrage (*padding*) de telle que sorte l'image en sortie soit de la même taille que l'image en entrée.\n",
        "* la fonction d'activation sigmoïde.\n",
        "* une couche de regroupement par le maximum avec un noyau de taille $2 \\times 2$ et un pas de $2$.\n",
        "* une couche de convolution avec $16$ canaux en sortie, un noyau de taille $5 \\times 5$ et sans rembourrage.\n",
        "* la fonction d'activation sigmoïde.\n",
        "* une couche de regroupement par le maximum avec un noyau de taille $2 \\times 2$ et un pas de $2$.\n",
        "* une couche d'aplatissement (*flatten*).\n",
        "* une couche linéaire avec une entrée de taille $400$ et une sortie de taille $256$.\n",
        "* la fonction d'activation sigmoïde.\n",
        "* une couche linéaire avec une sortie de taille $128$.\n",
        "* la fonction d'activation sigmoïde.\n",
        "* une couche linéaire avec une sortie de taille $26$.\n",
        "\n",
        "Voici les liens vers les documentations des classes correspondantes :\n",
        "[`torch.nn.Conv2d()`](https://pytorch.org/docs/stable/generated/torch.nn.Conv2d.html),\n",
        "[`torch.nn.Sigmoid()`](https://pytorch.org/docs/stable/generated/torch.nn.Sigmoid.html),\n",
        "[`torch.nn.MaxPool2d()`](https://pytorch.org/docs/stable/generated/torch.nn.MaxPool2d.html),\n",
        "[`torch.nn.Flatten()`](https://pytorch.org/docs/stable/generated/torch.nn.Flatten.html) et\n",
        "[`torch.nn.Linear()`](https://pytorch.org/docs/stable/generated/torch.nn.Linear.html)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TyeZ0obVyoEw"
      },
      "outputs": [],
      "source": [
        "class LeNet5(L.LightningModule):  # La classe hérite de la classe lightning.LightningModule\n",
        "    def __init__(self):\n",
        "        \"\"\"Constructeur.\n",
        "\n",
        "        Dans le constructeur, on exécute le constructeur de la clase mère et on définit\n",
        "        toutes les couches et fonctions d'activation de notre réseau de neurones.\n",
        "        \"\"\"\n",
        "        super().__init__()  # Toujours exécuter le constructeur de la classe mère\n",
        "\n",
        "        ### BEGIN TODO ###\n",
        "        # Initialisation du modèle\n",
        "        #### END TODO ####\n",
        "\n",
        "        # Initialisation de la fonction de perte\n",
        "        self.loss = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "        # Initialisation des métriques\n",
        "        self.accuracy_train = Accuracy(task=\"multiclass\", num_classes=26)\n",
        "        self.accuracy_val = Accuracy(task=\"multiclass\", num_classes=26)\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"Implémente la passe avant.\n",
        "\n",
        "        L'argument x est un tenseur correspondant soit à l'entrée une seule\n",
        "        observation soit aux entrées d'un lot d'observations.\n",
        "        \"\"\"\n",
        "        ### BEGIN TODO ###\n",
        "        # y =\n",
        "        #### END TODO ####\n",
        "        return y\n",
        "\n",
        "    def step(self, batch, dataset):\n",
        "        \"\"\"Effectue une étape.\n",
        "\n",
        "        Une étape consiste à passer d'un lot d'observations (l'argument batch)\n",
        "        à l'évaluation de la fonction de coût pour ce lot d'observations.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        batch : tuple\n",
        "            Un lot d'observations. Le premier élément du tuple est le lot\n",
        "            des entrées, le second est le lot des labels.\n",
        "\n",
        "        dataset : {\"training\", \"validation\"}\n",
        "            Jeu de données utilisé.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        loss : Tensor, shape = (1,)\n",
        "            La fonction de coût pour ce lot d'observations.\n",
        "        \"\"\"\n",
        "        X, y = batch  # X correspond aux images, y aux classes\n",
        "        logits = self(X)  # Passe avant, qui renvoie les logits\n",
        "        loss = self.loss(logits, y)  # Évaluation de la fonction de coût\n",
        "        y_pred = logits.argmax(1)  # Prédictions du modèle\n",
        "\n",
        "        if dataset == \"training\":\n",
        "            metric = self.accuracy_train\n",
        "            name = \"train\"\n",
        "            bar_step = True\n",
        "        else:\n",
        "            metric = self.accuracy_val\n",
        "            name = \"val\"\n",
        "            bar_step = False\n",
        "\n",
        "        acc = metric(y_pred, y)\n",
        "        self.log(f\"loss_{name}\", loss, prog_bar=bar_step, on_step=bar_step, on_epoch=True)\n",
        "        self.log(f\"accuracy_{name}\", acc, prog_bar=bar_step, on_step=bar_step, on_epoch=True)\n",
        "\n",
        "        return loss\n",
        "\n",
        "    def training_step(self, batch):\n",
        "        \"\"\"Effectue une étape d'entraînement.\"\"\"\n",
        "        return self.step(batch, \"training\")\n",
        "\n",
        "    def validation_step(self, batch):\n",
        "        \"\"\"Effectue une étape de validation.\"\"\"\n",
        "        return self.step(batch, \"validation\")\n",
        "\n",
        "    def on_train_start(self):\n",
        "        \"\"\"Code exécuté au début de l'entraînement.\"\"\"\n",
        "        string = f\"Version {self.trainer.logger.version}\"\n",
        "        print(f\"{string}\\n{'=' * len(string)}\\n\")\n",
        "\n",
        "    def on_train_epoch_end(self):\n",
        "        \"\"\"Code exécuté à la fin de chaque époque d'entraînement.\"\"\"\n",
        "        metrics = self.trainer.callback_metrics\n",
        "        string = (f\"\"\"\n",
        "            Époque {self.trainer.current_epoch + 1} / {self.trainer.max_epochs}\n",
        "            -------------------------------------------------\n",
        "            |     Jeu      | Fonction de perte | Exactitude |\n",
        "            | ------------ | ----------------- | ---------- |\n",
        "            | Entraînement |{metrics['loss_train'].item():^19.5f}|{metrics['accuracy_train'].item():^12.3%}|\n",
        "            |  Validation  |{metrics['loss_val'].item():^19.5f}|{metrics['accuracy_val'].item():^12.3%}|\n",
        "            -------------------------------------------------\n",
        "        \"\"\")\n",
        "        string = '\\n'.join([line.strip() for line in string.strip().split('\\n')])\n",
        "        print(string, \"\\n\")\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        \"\"\"Configure l'algorithme d'optimisation à utiliser.\"\"\"\n",
        "        optimizer = torch.optim.Adam(self.parameters())\n",
        "        return optimizer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cpOWs9qryoEw"
      },
      "source": [
        "### Question 10\n",
        "\n",
        "Affichez un résumé de cette architecture. Combien de paramètres entraînables a cette architecture ?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dwmxpOuGyoEx"
      },
      "outputs": [],
      "source": [
        "# TODO"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mOCgjuWpyoEx"
      },
      "source": [
        "**Réponse** : TODO"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Agh7K6dZyoEx"
      },
      "source": [
        "### Question 11\n",
        "\n",
        "Entraînez votre nouveau réseau de neurones pendant 10 époques. Comparez sa performance à celle du modèle précédent."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a5F_PNxDyoEx"
      },
      "outputs": [],
      "source": [
        "model_lenet = LeNet5()\n",
        "\n",
        "trainer_lenet = L.Trainer(\n",
        "    max_epochs=10,\n",
        "    enable_model_summary=False,  # supprimer le résumé du modèle\n",
        "    logger=CSVLogger('.'),  # sauvegarder les résultats dans un fichier CSV\n",
        "    num_sanity_val_steps=0,  # ne pas effectuer d'étape de validation avant l'entraînement\n",
        "    callbacks=[TQDMProgressBar(refresh_rate=100)]  # mettre à jour la barre de progression tous les 100 lots\n",
        ")\n",
        "\n",
        "trainer_lenet.fit(\n",
        "    model=model_lenet,\n",
        "    train_dataloaders=dataloader_train,\n",
        "    val_dataloaders=dataloader_val\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7LgXgslWyoEx"
      },
      "outputs": [],
      "source": [
        "plot_loss_accuracy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ul2UFig-yoEx"
      },
      "source": [
        "**Réponse** : TODO"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}